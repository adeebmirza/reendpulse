{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3261b853-f53e-4656-96f2-432216639c84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting confluent-kafka\n  Downloading confluent_kafka-2.8.2-cp39-cp39-manylinux_2_28_x86_64.whl (3.8 MB)\nInstalling collected packages: confluent-kafka\nSuccessfully installed confluent-kafka-2.8.2\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install confluent-kafka \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55bb0fc9-a676-4bef-8843-d70ab0806446",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting pymongo\n  Downloading pymongo-4.11.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (921 kB)\nCollecting dnspython<3.0.0,>=1.16.0\n  Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\nInstalling collected packages: dnspython, pymongo\nSuccessfully installed dnspython-2.7.0 pymongo-4.11.3\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70600902-564e-48ec-89ac-0154a1caa694",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/databricks/python_shell/scripts/db_ipykernel_launcher.py\", line 83, in <module>\n    app.shell.run_line_magic(\"matplotlib\", \"inline\")\n  File \"/databricks/python/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2309, in run_line_magic\n    result = fn(*args, **kwargs)\n  File \"/databricks/python/lib/python3.9/site-packages/IPython/core/magics/pylab.py\", line 99, in matplotlib\n    gui, backend = self.shell.enable_matplotlib(args.gui.lower() if isinstance(args.gui, str) else args.gui)\n  File \"/databricks/python/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3458, in enable_matplotlib\n    from matplotlib_inline.backend_inline import configure_inline_support\n  File \"/databricks/python/lib/python3.9/site-packages/matplotlib_inline/backend_inline.py\", line 6, in <module>\n    import matplotlib\n  File \"/databricks/python/lib/python3.9/site-packages/matplotlib/__init__.py\", line 109, in <module>\n    from . import _api, _version, cbook, docstring, rcsetup\n  File \"/databricks/python/lib/python3.9/site-packages/matplotlib/rcsetup.py\", line 27, in <module>\n    from matplotlib.colors import Colormap, is_color_like\n  File \"/databricks/python/lib/python3.9/site-packages/matplotlib/colors.py\", line 56, in <module>\n    from matplotlib import _api, cbook, scale\n  File \"/databricks/python/lib/python3.9/site-packages/matplotlib/scale.py\", line 23, in <module>\n    from matplotlib.ticker import (\n  File \"/databricks/python/lib/python3.9/site-packages/matplotlib/ticker.py\", line 136, in <module>\n    from matplotlib import transforms as mtransforms\n  File \"/databricks/python/lib/python3.9/site-packages/matplotlib/transforms.py\", line 46, in <module>\n    from matplotlib._path import (\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install --upgrade numpy tensorflow matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b82f697-50ac-49e8-b37f-957e7e3e8662",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting nltk\n  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\nCollecting regex>=2021.8.3\n  Downloading regex-2024.11.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (780 kB)\nCollecting tqdm\n  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.9/site-packages (from nltk) (1.1.1)\nRequirement already satisfied: click in /databricks/python3/lib/python3.9/site-packages (from nltk) (8.0.4)\nInstalling collected packages: tqdm, regex, nltk\nSuccessfully installed nltk-3.9.1 regex-2024.11.6 tqdm-4.67.1\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d5c3cdc-56ae-45df-913b-5e59982598b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to MongoDB\n✅ Kafka Consumer Subscribed to 'trendpulse'\n🔄 Waiting for messages from Kafka...\n✅ Post by Adeeeb: I hate this product | Sentiment: Negative\n✅ Comment by Adeeeb: i love it\n | Sentiment: Positive\n✅ Comment by Adeeeb: what rubbish is this | Sentiment: Neutral\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from confluent_kafka import Consumer, KafkaException\n",
    "from pymongo import MongoClient\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "# Download VADER if not already present\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# MongoDB Configuration\n",
    "MONGO_URI = \"mongodb+srv://adeeb:adeeb@adeeb.vz59b.mongodb.net/?retryWrites=true&w=majority&appName=adeeb\"\n",
    "DB_NAME = \"trendpulse\"\n",
    "COLLECTION_NAME = \"posts_comments\"\n",
    "\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[DB_NAME]\n",
    "collection = db[COLLECTION_NAME]\n",
    "print(\"✅ Connected to MongoDB\")\n",
    "\n",
    "# Kafka Consumer Configuration\n",
    "conf = {\n",
    "    'bootstrap.servers': \"pkc-921jm.us-east-2.aws.confluent.cloud:9092\",\n",
    "    'security.protocol': \"SASL_SSL\",\n",
    "    'sasl.mechanisms': \"PLAIN\",\n",
    "    'sasl.username': '6KE3HKBM46CFQYGL',\n",
    "    'sasl.password': 'uD/s8CeKResFVUYM1Psj3E0QbdHq+BI5mn03VkLMicY8jBm/o/sd1JA8D74xGskn',\n",
    "    'group.id': 'consumer-group-1',\n",
    "    'auto.offset.reset': 'earliest'\n",
    "}\n",
    "\n",
    "consumer = Consumer(conf)\n",
    "consumer.subscribe(['trendpulse'])\n",
    "print(\"✅ Kafka Consumer Subscribed to 'trendpulse'\")\n",
    "\n",
    "def predict_sentiment_vader(text):\n",
    "    \"\"\"Uses VADER to classify text as Positive, Negative, or Neutral.\"\"\"\n",
    "    scores = sia.polarity_scores(text)\n",
    "    compound = scores['compound']\n",
    "\n",
    "    if compound >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif compound <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "print(\"🔄 Waiting for messages from Kafka...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        msg = consumer.poll(1.0)\n",
    "        if msg is None:\n",
    "            continue\n",
    "        if msg.error():\n",
    "            print(f\"❌ Kafka Error: {msg.error()}\")\n",
    "            continue\n",
    "\n",
    "        # Process Kafka Message\n",
    "        data = json.loads(msg.value().decode('utf-8'))\n",
    "        name = data.get(\"name\")\n",
    "        message_type = data.get(\"type\")\n",
    "        message = data.get(\"message\")\n",
    "\n",
    "        # Perform Sentiment Analysis with VADER\n",
    "        sentiment = predict_sentiment_vader(message)\n",
    "\n",
    "        # Store in MongoDB\n",
    "        record = {\n",
    "            \"name\": name,\n",
    "            \"type\": message_type,\n",
    "            \"message\": message,\n",
    "            \"sentiment\": sentiment\n",
    "        }\n",
    "        collection.insert_one(record)\n",
    "\n",
    "        # Print to console\n",
    "        print(f\"✅ {message_type} by {name}: {message} | Sentiment: {sentiment}\")\n",
    "\n",
    "except KafkaException as e:\n",
    "    print(f\"❌ Kafka Consumer Error: {e}\")\n",
    "finally:\n",
    "    consumer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12e30329-1867-476f-be25-40b4612de58f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting snowflake-connector-python\n  Downloading snowflake_connector_python-3.14.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\nRequirement already satisfied: filelock<4,>=3.5 in /usr/local/lib/python3.9/dist-packages (from snowflake-connector-python) (3.9.0)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (2021.10.8)\nCollecting pyjwt<3.0.0\n  Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (21.3)\nCollecting pyOpenSSL<26.0.0,>=22.0.0\n  Downloading pyOpenSSL-25.0.0-py3-none-any.whl (56 kB)\nCollecting sortedcontainers>=2.4.0\n  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (3.3)\nCollecting tomlkit\n  Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\nCollecting typing_extensions<5,>=4.3\n  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\nCollecting asn1crypto<2.0.0,>0.24.0\n  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\nRequirement already satisfied: urllib3<2.0.0,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (1.26.9)\nRequirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from snowflake-connector-python) (2.6.2)\nRequirement already satisfied: pytz in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (2021.3)\nRequirement already satisfied: cffi<2.0.0,>=1.9 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (1.15.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (2.0.4)\nRequirement already satisfied: cryptography>=3.1.0 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (3.4.8)\nRequirement already satisfied: requests<3.0.0 in /databricks/python3/lib/python3.9/site-packages (from snowflake-connector-python) (2.27.1)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.9/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.21)\nCollecting cryptography>=3.1.0\n  Downloading cryptography-44.0.2-cp39-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging->snowflake-connector-python) (3.0.4)\nInstalling collected packages: typing-extensions, cryptography, tomlkit, sortedcontainers, pyOpenSSL, pyjwt, asn1crypto, snowflake-connector-python\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 4.1.1\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f6ec05f8-431c-49b7-852f-25413543c7d1\n    Can't uninstall 'typing-extensions'. No files were found to uninstall.\n  Attempting uninstall: cryptography\n    Found existing installation: cryptography 3.4.8\n    Not uninstalling cryptography at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f6ec05f8-431c-49b7-852f-25413543c7d1\n    Can't uninstall 'cryptography'. No files were found to uninstall.\nSuccessfully installed asn1crypto-1.5.1 cryptography-44.0.2 pyOpenSSL-25.0.0 pyjwt-2.10.1 snowflake-connector-python-3.14.0 sortedcontainers-2.4.0 tomlkit-0.13.2 typing-extensions-4.12.2\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install snowflake-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff9dfe5f-c8ba-4520-86fa-d338b45f8699",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to MongoDB\n✅ Snowflake updated with latest sentiment counts.\n"
     ]
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "\n",
    "# MongoDB Configuration\n",
    "MONGO_URI = \"mongodb+srv://adeeb:adeeb@adeeb.vz59b.mongodb.net/?retryWrites=true&w=majority&appName=adeeb\"\n",
    "DB_NAME = \"trendpulse\"\n",
    "COLLECTION_NAME = \"posts_comments\"\n",
    "\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[DB_NAME]\n",
    "collection = db[COLLECTION_NAME]\n",
    "print(\"✅ Connected to MongoDB\")\n",
    "\n",
    "# Snowflake Configuration\n",
    "SNOWFLAKE_CONFIG = {\n",
    "    \"user\": \"ADEEBM3\",\n",
    "    \"password\": \"goodnightadeebM1#\",\n",
    "    \"account\": \"ICULZLT-NP63719\",\n",
    "    \"warehouse\": \"COMPUTE_WH\",\n",
    "    \"database\": \"ADEEB\",\n",
    "    \"schema\": \"PUBLIC\"\n",
    "}\n",
    "\n",
    "def connect_snowflake():\n",
    "    \"\"\"Establish and return a Snowflake connection.\"\"\"\n",
    "    return snowflake.connector.connect(**SNOWFLAKE_CONFIG)\n",
    "\n",
    "def fetch_sentiment_counts():\n",
    "    \"\"\"Fetches aggregated sentiment counts from MongoDB.\"\"\"\n",
    "    today = datetime.today().date()\n",
    "    \n",
    "    pipeline = [\n",
    "        {\"$match\": {\"timestamp\": {\"$gte\": datetime.combine(today, datetime.min.time())}}},\n",
    "        {\"$group\": {\n",
    "            \"_id\": \"$sentiment\",\n",
    "            \"count\": {\"$sum\": 1}\n",
    "        }}\n",
    "    ]\n",
    "    \n",
    "    results = collection.aggregate(pipeline)\n",
    "    \n",
    "    sentiment_counts = {\"positive\": 0, \"negative\": 0, \"neutral\": 0}\n",
    "    for result in results:\n",
    "        sentiment_counts[result[\"_id\"].lower()] = result[\"count\"]\n",
    "    \n",
    "    return sentiment_counts\n",
    "\n",
    "def update_snowflake():\n",
    "    \"\"\"Updates Snowflake with aggregated sentiment data.\"\"\"\n",
    "    conn = connect_snowflake()\n",
    "    cursor = conn.cursor()\n",
    "    today = datetime.today().date()\n",
    "\n",
    "    sentiment_counts = fetch_sentiment_counts()\n",
    "    \n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM sentiment_insights WHERE date = '{today}'\")\n",
    "    exists = cursor.fetchone()[0]\n",
    "\n",
    "    if exists == 0:\n",
    "        cursor.execute(f\"\"\"\n",
    "            INSERT INTO sentiment_insights (date, positive, negative, neutral)\n",
    "            VALUES ('{today}', {sentiment_counts['positive']}, {sentiment_counts['negative']}, {sentiment_counts['neutral']})\n",
    "        \"\"\")\n",
    "    else:\n",
    "        cursor.execute(f\"\"\"\n",
    "            UPDATE sentiment_insights\n",
    "            SET positive = {sentiment_counts['positive']},\n",
    "                negative = {sentiment_counts['negative']},\n",
    "                neutral = {sentiment_counts['neutral']}\n",
    "            WHERE date = '{today}'\n",
    "        \"\"\")\n",
    "\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(f\"✅ Snowflake updated with latest sentiment counts.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    update_snowflake()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "574c718f-48f2-490e-ab67-6732223fc5c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE sentiment_insights (\n",
    "    date DATE PRIMARY KEY,\n",
    "    total_posts INT,\n",
    "    total_comments INT,\n",
    "    positive INT,\n",
    "    negative INT,\n",
    "    neutral INT\n",
    ");\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Sentiment",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
